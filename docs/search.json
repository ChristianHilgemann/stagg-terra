[{"path":"https://tcarleton.github.io/stagg/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 stagg authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://tcarleton.github.io/stagg/articles/data_sources.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using data from climateR or other sources with stagg","text":"vignette demonstrates use stagg package data climateR, well data sources temporal metadata format stagg accepts layer names. First, load packages used vignette.","code":"library(climateR) # Obtain climate data library(tigris) # Polygons to request and aggregate climate data over library(stagg) # Aggregate the climate data"},{"path":"https://tcarleton.github.io/stagg/articles/data_sources.html","id":"climater-example-working-with-gridmet-data","dir":"Articles","previous_headings":"","what":"climateR example: Working with GridMET Data","title":"Using data from climateR or other sources with stagg","text":"climateR package provides access data various sources, GridMET CHIRPS. raster layer names data retrieved climateR, like ERA5 data, compatible stagg therefore can used without additional steps. Specifically, layer name format compatible stagg uses character-date-time character-date format following string header, start date-time temporal time steps raster stack must specified staggregate_*(). example, ERA5 uses format x2021.01.01.00.00.00 x2021.01.01, data retrieved using climateR uses format variable_2021-01-01.","code":""},{"path":"https://tcarleton.github.io/stagg/articles/data_sources.html","id":"load-new-jersey-counties","dir":"Articles","previous_headings":"climateR example: Working with GridMET Data","what":"Load New Jersey Counties","title":"Using data from climateR or other sources with stagg","text":"First, load county boundaries New Jersey using tigris package.","code":"nj_counties <- tigris::counties(\"NJ\")"},{"path":"https://tcarleton.github.io/stagg/articles/data_sources.html","id":"retrieve-gridmet-data","dir":"Articles","previous_headings":"climateR example: Working with GridMET Data","what":"Retrieve GridMET Data","title":"Using data from climateR or other sources with stagg","text":"Next, use climateR package retrieve precipitation data GridMET New Jersey counties year 2010. can print layer names ensure compatibility stagg.","code":"gridmet_pr <- climateR::getGridMET(   AOI = nj_counties,   varname = \"pr\",   startDate = \"2010-01-01\",   endDate  = \"2010-12-31\" )[[1]] |>     raster::stack() names(gridmet_pr[[1:3]]) # Print the first three layer names #> [1] \"pr_2010.01.01\" \"pr_2010.01.02\" \"pr_2010.01.03\""},{"path":"https://tcarleton.github.io/stagg/articles/data_sources.html","id":"calculate-overlay-weights","dir":"Articles","previous_headings":"climateR example: Working with GridMET Data","what":"Calculate Overlay Weights","title":"Using data from climateR or other sources with stagg","text":"calculate overlay weights New Jersey counties using retrieved GridMET data.","code":"county_weights <- stagg::overlay_weights(   polygons = nj_counties,       # Simple features object with the desired polygons   polygon_id_col = \"COUNTYFP\",  # Column name containing polygon identifiers   grid = gridmet_pr             # Raster layer with the same coordinate system and spatial resolution as the climate data ) #> Checking for raster/polygon alignment #> Extracting raster polygon overlap #> Checking sum of weights within polygons #> All weights sum to 1.  print(county_weights, digits = 4) #>           x     y poly_id    w_area w_sum #>       <num> <num>  <char>     <num> <num> #>    1: 285.2 41.36     037 0.0007648     1 #>    2: 285.3 41.36     037 0.0029719     1 #>    3: 285.3 41.36     037 0.0038060     1 #>    4: 285.4 41.36     037 0.0001875     1 #>    5: 285.2 41.32     037 0.0022975     1 #>   ---                                     #> 1891: 285.4 40.19     021 0.0095147     1 #> 1892: 285.3 40.15     021 0.0047411     1 #> 1893: 285.3 40.15     021 0.0010524     1 #> 1894: 285.4 40.15     021 0.0111197     1 #> 1895: 285.4 40.15     021 0.0116498     1"},{"path":"https://tcarleton.github.io/stagg/articles/data_sources.html","id":"perform-polynomial-aggregation","dir":"Articles","previous_headings":"climateR example: Working with GridMET Data","what":"Perform Polynomial Aggregation","title":"Using data from climateR or other sources with stagg","text":"perform polynomial aggregation GridMET data using calculated overlay weights.","code":"polynomial_output <- stagg::staggregate_polynomial(      data = gridmet_pr,                # The GridMET data retrived from ClimateR      overlay_weights = county_weights, # Weights for grid cells within each county                                      # in New Jersey      daily_agg = \"none\",               # Because climateR provides data at the                                      # daily level already, it is not necessary                                     # to aggregate it up. If it were finer and                                     # we did want to aggregate it, we would                                      # choose \"sum\" since we would want the sum                                      # of precipitation over the time_agg of                                      # choice.       time_agg = \"month\",               # The temporal level to aggregate daily                                      # transformed values to. Current options are                                      # \"hour\", day\", \"month\", and \"year\". Note                                      # that \"hour\" is only available if daily_agg                                     # is set to \"none\"      degree = 3                        # The highest order of the polynomial. Here                                      # this will create variable 3 columns:                                      # order_1, order_2, and order_3   ) #> Skipping pre-transformation aggregation to daily level #> Executing polynomial transformation #> Aggregating by polygon and month  polynomial_output #>       year month poly_id   order_1   order_2    order_3 #>      <num> <num>  <char>     <num>     <num>      <num> #>   1:  2010     1     037  56.75739 1327.2879  39806.128 #>   2:  2010     2     037  97.13325 2434.7100  80308.805 #>   3:  2010     3     037 214.54942 9825.3591 563559.235 #>   4:  2010     4     037  72.66265 1221.0374  22493.601 #>   5:  2010     5     037  77.19771 1183.7247  23434.094 #>  ---                                                    #> 266:  2010     8     021  32.03729  276.7235   4083.636 #> 267:  2010     9     021 129.12420 4667.6112 265225.311 #> 268:  2010    10     021  60.02752  520.8648   5385.785 #> 269:  2010    11     021  60.80051  809.1176  13799.290 #> 270:  2010    12     021  73.83445 1502.6363  33897.406"},{"path":"https://tcarleton.github.io/stagg/articles/data_sources.html","id":"using-data-from-any-source-using-manual-time-specification","dir":"Articles","previous_headings":"","what":"Using data from any source using manual time specification","title":"Using data from climateR or other sources with stagg","text":"data types layer names follow stagg naming convention can also used stagg specifying start date time interval data calling staggregate_*(). First, rename layers format compatible stagg. can still use staggregate way get output, simply manually specify start_date time_interval data using. new output identical one obtained .","code":"names(gridmet_pr) <- rep(NA, length(names(gridmet_pr))) names(gridmet_pr[[1:3]]) # Print the first three layer names #> [1] \"layer.1\" \"layer.2\" \"layer.3\" polynomial_output <- stagg::staggregate_polynomial(      data = gridmet_pr,                # The GridMET data retrived from ClimateR,                                      # but with NA layer names      overlay_weights = county_weights,       daily_agg = \"none\",                 time_agg = \"month\",             start_date = \"2010-01-01\",        # Our data starts on January 1, 2010      time_interval = \"1 day\",          # Our data has a time interval of one day      degree = 3   ) #> Rewriting the data's temporal metadata (layer names) to reflect a dataset starting on the supplied start date and with a temporal interval of 1 day #> Skipping pre-transformation aggregation to daily level #> Executing polynomial transformation #> Aggregating by polygon and month polynomial_output #>       year month poly_id   order_1   order_2    order_3 #>      <num> <num>  <char>     <num>     <num>      <num> #>   1:  2010     1     037  56.75739 1327.2879  39806.128 #>   2:  2010     2     037  97.13325 2434.7100  80308.805 #>   3:  2010     3     037 214.54942 9825.3591 563559.235 #>   4:  2010     4     037  72.66265 1221.0374  22493.601 #>   5:  2010     5     037  77.19771 1183.7247  23434.094 #>  ---                                                    #> 266:  2010     8     021  32.03729  276.7235   4083.636 #> 267:  2010     9     021 129.12420 4667.6112 265225.311 #> 268:  2010    10     021  60.02752  520.8648   5385.785 #> 269:  2010    11     021  60.80051  809.1176  13799.290 #> 270:  2010    12     021  73.83445 1502.6363  33897.406"},{"path":"https://tcarleton.github.io/stagg/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"First Last. Author, maintainer.","code":""},{"path":"https://tcarleton.github.io/stagg/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Last F (2024). stagg: Spatiotemporal Aggregation Climate Data. R package version 0.0.0.9000, https://github.com/tcarleton/stagg, https://tcarleton.github.io/stagg.","code":"@Manual{,   title = {stagg: Spatiotemporal Aggregation for Climate Data},   author = {First Last},   year = {2024},   note = {R package version 0.0.0.9000, https://github.com/tcarleton/stagg},   url = {https://tcarleton.github.io/stagg}, }"},{"path":"https://tcarleton.github.io/stagg/index.html","id":"stagg","dir":"","previous_headings":"","what":"Spatiotemporal Aggregation for Climate Data","title":"Spatiotemporal Aggregation for Climate Data","text":"R Package stagg aims harmonize preparation spatiotemporal raster data, particular climate observations, use statistical analyses. allows efficient use researchers’ time, avoids common missteps. end goal greater quantity quality research study coupled human-geophysical systems. documentation, including working paper, AGU conference poster, cheat sheet available .","code":""},{"path":"https://tcarleton.github.io/stagg/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Spatiotemporal Aggregation for Climate Data","text":"Although stagg yet CRAN, can install development version stagg GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"tcarleton/stagg\")"},{"path":"https://tcarleton.github.io/stagg/index.html","id":"abstract","dir":"","previous_headings":"","what":"Abstract","title":"Spatiotemporal Aggregation for Climate Data","text":"increasing availability high-resolution climate data greatly expanded study climate impacts humans society. However, processing multi-dimensional datasets poses significant challenges researchers growing field, social scientists. paper introduces stagg “space-time aggregator”, new R package streamlines three critical components climate data processing impact analysis: nonlinear transformation, spatial temporal aggregation, spatial weighting additional social economic variables. package consolidates entire data processing pipeline just lines code, lowering barriers entry researchers interdisciplinary field climate impacts analysis facilitating larger diverse research community. stagg designed used ERA5 reanalysis climate data, can easily modified input data. paper provides overview stagg’s functions data processing pipeline, followed applied example demonstrating package’s utility climate impacts research. stagg potential valuable tool generating evidence-based estimates likely impacts future climate change quantifying social cost carbon.","code":""},{"path":"https://tcarleton.github.io/stagg/index.html","id":"workflow","dir":"","previous_headings":"","what":"Workflow","title":"Spatiotemporal Aggregation for Climate Data","text":"example code commentary aimed demonstrating expected typical usage. order steps important, output step used one follows . Important stagg package currently include functions download climate data. many packages can used download climate data. example, climateR provides access climate datasets 2000 different data providers. ERA5 climate data can download ecmwfr, provides interface two European Centre Medium-Range Weather Forecast APIs. KrigR package provides helpful wrapper function ecmwfr package enable direct downloading ERA5 climate data R. ECMWF also provides general guide downloading ERA5 data. example use ERA5 climate data, package includes global raster layer ERA5 climate data can used secondary_weights() overlay_weights() functions. However, types climate data can used. compatibility stagg climate data : - raster raster stack (e.g., raster::raster() raster::stack(); can originally stored formats netCDF .tif) - least yearly temporal resolution, since coarse temporal aggregation offered stagg yearly. - sub-daily, number layers per day consistent. default, hourly time steps assumed (.e. 24 time steps per day), though different number can specified using time_interval argument staggregate_*() functions. - order temporal aggregation happen properly, stagg must way knowing temporal information associated raster stack aggregated. can achieved one two ways: - layer names use character-date-time character-date format following string header, start date-time temporal time steps raster stack must specified staggregate_*(). example, ERA5 uses format x2021.01.01.00.00.00 x2021.01.01, data retrieved using climateR uses format variable_2021-01-01, compatible stagg. - specify start datetime temporal interval data staggregate_*() functions using start_date time_interval arguments.","code":"library(stagg) # Using polygons outlining counties of New Jersey as administrative regions nj_counties <- tigris::counties(\"NJ\")"},{"path":"https://tcarleton.github.io/stagg/index.html","id":"step-1-optional-resample-a-secondary-data-input-and-generate-secondary-weights-for-step-2","dir":"","previous_headings":"Workflow","what":"Step 1 (Optional): Resample a secondary data input and generate secondary weights for Step 2","title":"Spatiotemporal Aggregation for Climate Data","text":"common studying interactions human natural systems spatially aggregate climate data using weights derived another dataset interest, population cropland. allows user retrieve climate experienced humans crops within given administrative region. account , stagg allows conversion raster data.table weights via secondary_weights() function. weights can used compute weighted average climate data administrative region. following example shows one go generating cropland weights state New Jersey. can see output, secondary_weights() checks alignment, rotates secondary_raster coordinates necessary. also resamples data spatial resolution climate grid using bilinear interpolation, returns data.table latitudes, longitudes, cropland weights.","code":"cropland_weights <- secondary_weights(      secondary_raster = cropland_nj_2015,     # A raster layer of the secondary                                             # variable to generate weights from      grid = era5_grid,                        # A raster layer with the same                                             # coordinate system and spatial                                             # resolution as the climate data                                             # (defaults to the era5_grid).                                             # You can also pass in your climate                                             # data and the grid will be taken                                             # from its first layer      extent = \"full\"                          # The default is \"full\", which                                             # generates weights for entire                                             # secondary data raster. User has the                                             # option to define an extent for                                             # cropping the secondary_raster,                                             # which saves compute time. Input                                             # format must be compatible with                                             # raster::crop(), such as:                                            #    nj_extent <- sf::st_bbox(nj_counties)                                            #    nj_extent <- raster::extent(nj_counties)                                            #    nj_extent <- c(-76, -73, 38, 42) ) #> Loading required package: raster  #> Loading required package: sp  #> Checking for raster alignment  #> Longitude coordinates do not match. Aligning longitudes to standard coordinates.  #> Resampling secondary_raster  #> Creating a table of weights #Display resulting table cropland_weights #>           x     y    weight #>       <num> <num>     <num> #>   1: -76.25 41.75 0.2294976 #>   2: -76.00 41.75 0.2198315 #>   3: -75.75 41.75 0.1777267 #>   4: -75.50 41.75 0.1362904 #>   5: -75.25 41.75 0.1061073 #>  ---                        #> 178: -74.25 38.50 0.0000000 #> 179: -74.00 38.50 0.0000000 #> 180: -73.75 38.50 0.0000000 #> 181: -73.50 38.50 0.0000000 #> 182: -73.25 38.50 0.0000000"},{"path":"https://tcarleton.github.io/stagg/index.html","id":"step-2-overlay-administrative-regions-onto-the-datas-grid","dir":"","previous_headings":"Workflow","what":"Step 2: Overlay administrative regions onto the data’s grid","title":"Spatiotemporal Aggregation for Climate Data","text":"core part stagg’s functionality aggregate gridded data level administrative regions. order , first calculates portion region covered particular cell. weights may also scaled secondary weights calculated Step 1. accomplished using overlay_weights() function. can see function outputs multiple rows polygon, one every grid cell overlaps. column w_area represents proportion polygon falls within grid cell corresponding x y coordinates. included secondary_weights Step 1, , overlay_weights() also creates column named weight, determined normalizing secondary_weights w_area. used aggregation values. wish use w_area aggregating polygon, need run secondary_weights() can omit argument secondary_weights call overlay_weights(). Given information, can interpret top row output follows: 1.7% area county represented COUNTYFP 011 falls within grid cell 284.50 degrees longitude (0-360 range), 39.25 degrees latitude. appears particular pixel slightly cropland pixels polygon though, since cropland weight cell 3.1%.","code":"county_weights <- overlay_weights(      polygons = nj_counties,              # A simple features object with the                                         # desired polygons      polygon_id_col = \"COUNTYFP\",         # The name of the column containing                                         # polygons' identifiers      grid = era5_grid,                    # A raster layer with the same coordinate                                        # system and spatial resolution as the                                         # climate_data (defaults to the                                         # era5_grid). You can also pass in your                                         # climate data and a grid will be taken                                         # from its first layer      secondary_weights = cropland_weights # Optional output from Step 1, a table of                                        # weights, determined here by cropland in                                        # each grid cell ) #> Checking for raster/polygon alignment  #> Aligning longitudes to standard coordinates.  #> Extracting raster polygon overlap  #> Secondary weights fully overlap with the administrative regions.  #> Checking sum of weights within polygons  #> All weights sum to 1. # Display results print(county_weights, digits = 4) #>          x     y poly_id    w_area    weight #>      <num> <num>  <char>     <num>     <num> #>   1: 284.5 39.25     011 0.0172211 0.0360401 #>   2: 284.5 39.25     033 0.0058164 0.0060266 #>   3: 284.5 39.50     011 0.0170331 0.0307720 #>   4: 284.5 39.50     033 0.3550727 0.3175946 #>   5: 284.5 39.75     015 0.0219317 0.0193611 #>  ---                                         #> 137: 286.0 40.75     013 0.0095999 0.0057512 #> 138: 286.0 40.75     003 0.1828252 0.1307450 #> 139: 286.0 40.75     031 0.0065823 0.0028849 #> 140: 286.0 41.00     003 0.5410449 0.6773374 #> 141: 286.0 41.00     031 0.0007093 0.0005442"},{"path":"https://tcarleton.github.io/stagg/index.html","id":"step-3-transform-and-aggregate-data-using-the-staggregate_-family-of-functions","dir":"","previous_headings":"Workflow","what":"Step 3: Transform and aggregate data using the staggregate_* family of functions","title":"Spatiotemporal Aggregation for Climate Data","text":"completing Step 2, ready transform aggregate data. final step data ready use downstream statistical analyses. stagg package provides family functions perform final step, offering different type non-linear transformation. Regardless specific function,staggregate_*()’s workflow aggregate gridded values daily level (step can skipped specifying daily_agg = “none”, though recommended faster computation), perform transformation daily values, aggregate values administrative regions desired temporal scale based overlay_weights() output Step 2.","code":""},{"path":"https://tcarleton.github.io/stagg/index.html","id":"polynomial-transformation","dir":"","previous_headings":"Workflow > Step 3: Transform and aggregate data using the staggregate_* family of functions","what":"Polynomial Transformation","title":"Spatiotemporal Aggregation for Climate Data","text":"One common transformation create new variables raising value exponent. Treating new values independent variables within linear regression allows researchers identify non-linear trends within data. stagg prepares data type statistical analyses preserving high spatiotemporal resolution calculating new variables daily gridded values prior aggregating polygon monthly/yearly level staggregate_polynomial(). can see 3 variables created. order_1 represents original values, linearly aggregated county, monthly level. order_2 order_3 represent original values squared cubed, respectively, prior aggregated county monthly level. case, example 30 days temperature data polygon one row corresponding month present, June full year data, polygon appear 12 times. Note also passing time_agg = \"day\" create data.table 30 times longer, another column right month called day.","code":"polynomial_output <- staggregate_polynomial(      data = temp_nj_jun_2024_era5 - 273.15, # A raster brick of our primary data,                                           # typically but not necessarily climate                                           # data. For now, data must start at                                           # midnight and be hourly. We're                                           # converting from Kelvin to Celsius                                           # here.      overlay_weights = county_weights, # Output from Step 2, determined here by                                      # area-normalized cropland weights for grid                                      # cells within each county in New Jersey      daily_agg = \"average\",            # How to aggregate hourly values to the                                      # daily level (options are \"sum\", \"average\",                                     # and \"none\"). Here we want average daily                                      # temperature       time_agg = \"month\",               # The temporal level to aggregate daily                                      # transformed values to. Current options are                                      # \"hour\", day\", \"month\", and \"year\". Note                                      # that \"hour\" is only available if daily_agg                                     # is set to \"none\"      degree = 3                        # The highest order of the polynomial. Here                                      # this will create variable 3 columns:                                      # order_1, order_2, and order_3   ) #> Averaging over 24 layers per day to get daily values  #> Executing polynomial transformation  #> Aggregating by polygon and month # Display results polynomial_output #>      year month poly_id  order_1  order_2  order_3 #>     <num> <num>  <char>    <num>    <num>    <num> #>  1:  2024     6     011 729.4373 17894.66 442930.1 #>  2:  2024     6     033 733.7415 18118.51 451662.6 #>  3:  2024     6     015 729.0098 17892.01 443419.8 #>  4:  2024     6     009 686.3300 15807.50 366563.4 #>  5:  2024     6     007 730.9659 17987.04 446942.1 #>  6:  2024     6     041 684.4207 15918.44 377139.5 #>  7:  2024     6     019 705.7509 16878.38 410117.8 #>  8:  2024     6     001 724.9572 17682.29 435310.3 #>  9:  2024     6     005 726.9852 17802.18 440440.8 #> 10:  2024     6     021 721.3909 17561.50 432688.6 #> 11:  2024     6     027 687.8298 16056.75 381384.9 #> 12:  2024     6     037 663.3331 14985.01 345520.2 #> 13:  2024     6     023 718.5814 17424.03 427602.5 #> 14:  2024     6     035 710.1241 17067.68 416336.7 #> 15:  2024     6     029 720.6808 17499.87 429477.7 #> 16:  2024     6     025 711.0168 17042.99 413123.1 #> 17:  2024     6     039 702.9569 16690.27 401409.4 #> 18:  2024     6     013 698.6268 16473.52 393206.4 #> 19:  2024     6     031 670.6923 15279.34 354421.3 #> 20:  2024     6     017 704.8867 16733.28 401281.4 #> 21:  2024     6     003 688.9643 16026.13 377468.5 #>      year month poly_id  order_1  order_2  order_3"},{"path":"https://tcarleton.github.io/stagg/index.html","id":"restricted-cubic-spline-transformation","dir":"","previous_headings":"Workflow > Step 3: Transform and aggregate data using the staggregate_* family of functions","what":"Restricted Cubic Spline Transformation","title":"Spatiotemporal Aggregation for Climate Data","text":"Another type transformation stagg supports restricted cubic spline. , essentially, piecewise function 3rd degree polynomials intersect knots function’s first second derivatives continuous negative infinity positive infinity, function linear first knot last one. detailed explanation, well formula used transform data, can found . staggregate_spline() executes formula create K-2 new variables, K number knots, addition preserving original untransformed value variable. Computing knot locations can memory intensive therefore stagg package compute default knot locations. larger data sets, users might want load representative subset data calculate different quantiles help choosing knot locations. can see output looks similar table polynomial transformation. difference 4 - 2 (number knots minus two) new variables created. data now ready use regression.","code":"spline_output <- staggregate_spline(      data = temp_nj_jun_2024_era5 - 273.15, # A raster brick of our primary data,                                           # typically but not necessarily climate                                           # data. For now, data must start at                                           # midnight and be hourly. We're                                          # converting from Kelvin to Celsius                                           # here.      overlay_weights = county_weights, # Output from Step 2, determined here by                                      # area-normalized cropland weights for grid                                     # cells within each county in New Jersey.      daily_agg = \"average\",            # How to aggregate hourly values to the                                      # daily level, \"sum\" and \"average\" are the                                      # only options. Here we want average daily                                      # temperature      time_agg = \"month\",               # The temporal level to aggregate daily                                      # transformed values to. Current options are                                      # \"day\", \"month\", and \"year\"       knot_locs = c(0, 7.5, 12.5, 20)   # Where to place the knots  ) #> Averaging over 24 layers per day to get daily values  #> Executing spline transformation  #> Aggregating by polygon and month # Display output spline_output #>      year month poly_id    value   term_1   term_2 #>     <num> <num>  <char>    <num>    <num>    <num> #>  1:  2024     6     011 729.4373 303327.9 61769.48 #>  2:  2024     6     033 733.7415 306556.2 62576.55 #>  3:  2024     6     015 729.0098 303007.5 61689.39 #>  4:  2024     6     009 686.3300 270997.7 53686.97 #>  5:  2024     6     007 730.9659 304474.5 62056.15 #>  6:  2024     6     041 684.4207 269634.4 53356.41 #>  7:  2024     6     019 705.7509 285580.9 57335.39 #>  8:  2024     6     001 724.9572 299967.9 60929.49 #>  9:  2024     6     005 726.9852 301489.3 61309.89 #> 10:  2024     6     021 721.3909 297294.5 60261.31 #> 11:  2024     6     027 687.8298 272168.1 53986.38 #> 12:  2024     6     037 663.3331 253919.2 49442.69 #> 13:  2024     6     023 718.5814 295187.0 59734.38 #> 14:  2024     6     035 710.1241 288852.2 58151.92 #> 15:  2024     6     029 720.6808 296761.1 60127.84 #> 16:  2024     6     025 711.0168 289513.4 58315.97 #> 17:  2024     6     039 702.9569 283473.5 56806.76 #> 18:  2024     6     013 698.6268 280224.5 55994.31 #> 19:  2024     6     031 670.6923 259366.5 50793.73 #> 20:  2024     6     017 704.8867 284915.9 57166.60 #> 21:  2024     6     003 688.9643 272983.2 54184.80 #>      year month poly_id    value   term_1   term_2"},{"path":"https://tcarleton.github.io/stagg/index.html","id":"binning-transformation","dir":"","previous_headings":"Workflow > Step 3: Transform and aggregate data using the staggregate_* family of functions","what":"Binning Transformation","title":"Spatiotemporal Aggregation for Climate Data","text":"stagg can also divide daily values different bins specified user. can useful identifying outliers nonlinearities within data, accomplished calling staggregate_bin(). Like , output table features one row every county every time period specified time_agg argument. changed new column bin created, representing number days polygon value fell within bin timespan specified time_agg argument. outputs necessarily integers since polygon made pixels sorted bins weighted overlay_weights provided aggregated, , county level. specify bins, degrees Celsius, negative infinity 0, 0 2.5, 2.5 5, 5 7.5, 7.5 10, 10 infinity passing c(0, 2.5, 5, 7.5, 10) bin_break. staggregate_bin() draws bin pair breaks, adds edge bins encompass values minimum break maximum break.","code":"bin_output <- staggregate_bin(      data = temp_nj_jun_2024_era5 - 273.15, # A raster brick of our primary data,                                           # typically but not necessarily climate                                           # data. For now, data must start at                                           # midnight and be hourly. We're                                           # converting from Kelvin to Celsius                                          # here.      overlay_weights = county_weights,  # Output from Step 2, determined here by                                       # area-normalized cropland weights for grid                                       # cells within each county in New Jersey         daily_agg = \"average\",             # How to aggregate hourly values to the                                       # daily level, \"sum\" and \"average\" are the                                        # only options. Here we want average daily                                       # temperature.       time_agg = \"month\",                # The temporal level to aggregate daily                                        # transformed values to. Current options are                                      # \"day\", \"month\", and \"year\"       bin_breaks = c(0, 2.5, 5, 7.5, 10) # The values to split the data by ) #> Averaging over 24 layers per day to get daily values  #> Executing binning transformation  #> Aggregating by polygon and month # Display output bin_output #>      year month poly_id bin_ninf_to_0 bin_0_to_2.5 bin_2.5_to_5 bin_5_to_7.5 #>     <num> <num>  <char>         <num>        <num>        <num>        <num> #>  1:  2024     6     011             0            0            0            0 #>  2:  2024     6     033             0            0            0            0 #>  3:  2024     6     015             0            0            0            0 #>  4:  2024     6     009             0            0            0            0 #>  5:  2024     6     007             0            0            0            0 #>  6:  2024     6     041             0            0            0            0 #>  7:  2024     6     019             0            0            0            0 #>  8:  2024     6     001             0            0            0            0 #>  9:  2024     6     005             0            0            0            0 #> 10:  2024     6     021             0            0            0            0 #> 11:  2024     6     027             0            0            0            0 #> 12:  2024     6     037             0            0            0            0 #> 13:  2024     6     023             0            0            0            0 #> 14:  2024     6     035             0            0            0            0 #> 15:  2024     6     029             0            0            0            0 #> 16:  2024     6     025             0            0            0            0 #> 17:  2024     6     039             0            0            0            0 #> 18:  2024     6     013             0            0            0            0 #> 19:  2024     6     031             0            0            0            0 #> 20:  2024     6     017             0            0            0            0 #> 21:  2024     6     003             0            0            0            0 #>      year month poly_id bin_ninf_to_0 bin_0_to_2.5 bin_2.5_to_5 bin_5_to_7.5 #>     bin_7.5_to_10 bin_10_to_inf #>             <num>         <num> #>  1:             0            30 #>  2:             0            30 #>  3:             0            30 #>  4:             0            30 #>  5:             0            30 #>  6:             0            30 #>  7:             0            30 #>  8:             0            30 #>  9:             0            30 #> 10:             0            30 #> 11:             0            30 #> 12:             0            30 #> 13:             0            30 #> 14:             0            30 #> 15:             0            30 #> 16:             0            30 #> 17:             0            30 #> 18:             0            30 #> 19:             0            30 #> 20:             0            30 #> 21:             0            30 #>     bin_7.5_to_10 bin_10_to_inf"},{"path":"https://tcarleton.github.io/stagg/index.html","id":"degree-days-transformation","dir":"","previous_headings":"Workflow > Step 3: Transform and aggregate data using the staggregate_* family of functions","what":"Degree Days Transformation","title":"Spatiotemporal Aggregation for Climate Data","text":"final transformation offered degree days, measures degrees certain temperature threshold experienced (often) crops. used generate estimates piecewise functions. staggregate_degree_days() operates directly hourly values. Passing vector length n thresholds creates n + 1 columns, similar staggregate_bin() operates. value climate raster brick (stack), function determines thresholds value falls . example, value 15 falls 10 20. variables corresponding threshold pairs receive difference two thresholds (threshold_0_to_10 gets 10) variables (threshold_20_to_inf) get 0. variable value falls gets difference lower threshold value (threshold_10_to20 gets 5). low edge variable (threshold_ninf_to_0) unique measures far smallest threshold value falls. value -3 get 3 variable, value 0 receive 0 . values transformed way hourly values aggregated polygon level temporal scale desired staggregate_*() functions.","code":"staggregate_degree_days(   data = temp_nj_jun_2024_era5 - 273.15, # A raster brick of our primary data,                                           # typically but not necessarily climate                                           # data. For now, data must start at                                           # midnight and be hourly. We're                                          # converting from Kelvin to Celsius                                          # here.       overlay_weights = county_weights, # Output from Step 2, determined here by                                      # area-normalized cropland weights for grid                                      # cells within each county in New Jersey      # Note degree_days() does not take a daily_agg as it uses hourly values      time_agg = \"month\",               # The temporal level to aggregate daily                                       # transformed values to. Current options are                                     # \"day\", \"month\", and \"year\"       thresholds = c(0, 10, 20)        # Temperature thresholds between which                                     # separate regression coefficients can be                                     # estimated ) #> Skipping pre-transformation aggregation to daily level  #> Executing degree days transformation  #> Aggregating by polygon and month  #>      year month poly_id threshold_ninf_to_0 threshold_0_to_10 #>     <num> <num>  <char>               <num>             <num> #>  1:  2024     6     011                   0              7200 #>  2:  2024     6     033                   0              7200 #>  3:  2024     6     015                   0              7200 #>  4:  2024     6     009                   0              7200 #>  5:  2024     6     007                   0              7200 #>  6:  2024     6     041                   0              7200 #>  7:  2024     6     019                   0              7200 #>  8:  2024     6     001                   0              7200 #>  9:  2024     6     005                   0              7200 #> 10:  2024     6     021                   0              7200 #> 11:  2024     6     027                   0              7200 #> 12:  2024     6     037                   0              7200 #> 13:  2024     6     023                   0              7200 #> 14:  2024     6     035                   0              7200 #> 15:  2024     6     029                   0              7200 #> 16:  2024     6     025                   0              7200 #> 17:  2024     6     039                   0              7200 #> 18:  2024     6     013                   0              7200 #> 19:  2024     6     031                   0              7200 #> 20:  2024     6     017                   0              7200 #> 21:  2024     6     003                   0              7200 #>      year month poly_id threshold_ninf_to_0 threshold_0_to_10 #>     threshold_10_to_20 threshold_20_to_inf #>                  <num>               <num> #>  1:           7033.869            3272.625 #>  2:           6996.451            3413.344 #>  3:           6929.859            3366.375 #>  4:           7129.929            2141.990 #>  5:           6935.451            3407.730 #>  6:           6486.642            2739.455 #>  7:           6661.205            3076.817 #>  8:           6965.391            3233.581 #>  9:           6902.068            3345.578 #> 10:           6822.985            3290.398 #> 11:           6549.322            2758.592 #> 12:           6336.398            2383.596 #> 13:           6834.659            3211.294 #> 14:           6712.329            3130.650 #> 15:           6894.822            3201.517 #> 16:           6886.335            2978.067 #> 17:           6794.598            2876.367 #> 18:           6812.126            2754.916 #> 19:           6437.996            2458.619 #> 20:           6947.556            2769.725 #> 21:           6755.068            2580.074 #>     threshold_10_to_20 threshold_20_to_inf"},{"path":"https://tcarleton.github.io/stagg/reference/cropland_nj_2015.html","id":null,"dir":"Reference","previous_headings":"","what":"Cropland data for the state of New Jersey. — cropland_nj_2015","title":"Cropland data for the state of New Jersey. — cropland_nj_2015","text":"raster depicting cropland around state New Jersey. original data resolution 0.00025 latitude 0.00025 longitude comes Potapov et. al. dataset available https://glad.umd.edu/dataset/croplands. raster resampled resolution 0.025 latitude 0.025 longitude meet memory constraints.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/cropland_nj_2015.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cropland data for the state of New Jersey. — cropland_nj_2015","text":"","code":"cropland_nj_2015"},{"path":"https://tcarleton.github.io/stagg/reference/cropland_nj_2015.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cropland data for the state of New Jersey. — cropland_nj_2015","text":"object class RasterLayer dimension 150 x 140 x 1.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/cropland_world_2015_era5.html","id":null,"dir":"Reference","previous_headings":"","what":"Global cropland weights — cropland_world_2015_era5","title":"Global cropland weights — cropland_world_2015_era5","text":"data.table ERA5 resolution returned running secondary_weights() cropland data 2015","code":""},{"path":"https://tcarleton.github.io/stagg/reference/cropland_world_2015_era5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global cropland weights — cropland_world_2015_era5","text":"","code":"cropland_world_2015_era5"},{"path":"https://tcarleton.github.io/stagg/reference/cropland_world_2015_era5.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Global cropland weights — cropland_world_2015_era5","text":"object class data.table (inherits data.frame) 582400 rows 3 columns.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/era5_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Empty ERA5 grid. — era5_grid","title":"Empty ERA5 grid. — era5_grid","text":"empty raster layer global extent spatial resolution ERA5 data used resampling secondary raster.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/era5_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empty ERA5 grid. — era5_grid","text":"","code":"era5_grid"},{"path":"https://tcarleton.github.io/stagg/reference/era5_grid.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Empty ERA5 grid. — era5_grid","text":"object class RasterLayer dimension 721 x 1440 x 1.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/nj_counties.html","id":null,"dir":"Reference","previous_headings":"","what":"Polygons representing counties in the state of New Jersey. — nj_counties","title":"Polygons representing counties in the state of New Jersey. — nj_counties","text":"multipolygon object depicting county boundaries New Jersey, using census data available tigris package.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/nj_counties.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polygons representing counties in the state of New Jersey. — nj_counties","text":"","code":"nj_counties"},{"path":"https://tcarleton.github.io/stagg/reference/nj_counties.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Polygons representing counties in the state of New Jersey. — nj_counties","text":"object class sf (inherits data.frame) 21 rows 18 columns.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/overlay_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the spatial overlap between a raster and a set of polygons — overlay_weights","title":"Find the spatial overlap between a raster and a set of polygons — overlay_weights","text":"overlay_weights() function generates table weights mapping grid cell respective polygon(s) use staggregate_*() family functions.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/overlay_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the spatial overlap between a raster and a set of polygons — overlay_weights","text":"","code":"overlay_weights(   polygons,   polygon_id_col,   grid = era5_grid,   secondary_weights = NULL )"},{"path":"https://tcarleton.github.io/stagg/reference/overlay_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the spatial overlap between a raster and a set of polygons — overlay_weights","text":"polygons simple features polygon multipolygon object polygon_id_col name column polygons object unique identifier polygon grid raster layer spatial resolution data secondary_weights optional table secondary weights, output secondary_weights() function","code":""},{"path":"https://tcarleton.github.io/stagg/reference/overlay_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the spatial overlap between a raster and a set of polygons — overlay_weights","text":"data.table area weights possibly secondary weights cell within polygon","code":""},{"path":"https://tcarleton.github.io/stagg/reference/overlay_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the spatial overlap between a raster and a set of polygons — overlay_weights","text":"","code":"overlay_output_with_secondary_weights <- overlay_weights(   polygons = nj_counties, # Polygons outlining the 21 counties of New Jersey   polygon_id_col = \"COUNTYFP\", # The name of the column with the unique                                # county identifiers   grid = era5_grid, # The grid to use when extracting area weights (era5_grid is the                     # default)   secondary_weights = cropland_world_2015_era5 # Output from                                                # secondary_weights                                                # (cropland_world_2015_era5 is                                                # available to the# user)   ) #> Checking for raster/polygon alignment #> Aligning longitudes to standard coordinates. #> Extracting raster polygon overlap #> Secondary weights fully overlap with the administrative regions. #> Checking sum of weights within polygons #> All weights sum to 1.  head(overlay_output_with_secondary_weights) #>        x     y poly_id      w_area      weight #>    <num> <num>  <char>       <num>       <num> #> 1: 284.5 39.25     011 0.017221145 0.033565672 #> 2: 284.5 39.25     033 0.005816417 0.006236843 #> 3: 284.5 39.50     011 0.017033115 0.028784469 #> 4: 284.5 39.50     033 0.355072708 0.330109034 #> 5: 284.5 39.75     015 0.021931677 0.024382703 #> 6: 284.5 39.75     033 0.182386051 0.156198032    overlay_output_without_secondary_weights <- overlay_weights(   polygons = nj_counties, # Polygons outlining the 21 counties of New Jersey   polygon_id_col = \"COUNTYFP\" # The name of the column with the unique county                               # identifiers   ) #> Checking for raster/polygon alignment #> Aligning longitudes to standard coordinates. #> Extracting raster polygon overlap #> Checking sum of weights within polygons #> All weights sum to 1.  head(overlay_output_without_secondary_weights) #>         x     y poly_id       w_area w_sum #>     <num> <num>  <char>        <num> <num> #> 1: 285.00 41.25     037 0.0140156458     1 #> 2: 285.25 41.25     037 0.3241450630     1 #> 3: 285.50 41.25     037 0.2178277183     1 #> 4: 285.75 41.25     037 0.0002487302     1 #> 5: 285.00 41.00     037 0.0470109628     1 #> 6: 285.25 41.00     037 0.3165378806     1"},{"path":"https://tcarleton.github.io/stagg/reference/overlay_weights_nj.html","id":null,"dir":"Reference","previous_headings":"","what":"Area and cropland weights in ERA5 grid for New Jersey counties — overlay_weights_nj","title":"Area and cropland weights in ERA5 grid for New Jersey counties — overlay_weights_nj","text":"table weights returned running overlay_weights() nj_counties secondary cropland weights.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/overlay_weights_nj.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Area and cropland weights in ERA5 grid for New Jersey counties — overlay_weights_nj","text":"","code":"overlay_weights_nj"},{"path":"https://tcarleton.github.io/stagg/reference/overlay_weights_nj.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Area and cropland weights in ERA5 grid for New Jersey counties — overlay_weights_nj","text":"data.table 141 observations 5 variables x longitude, ranging 0 360 y latitude, ranging -90 90 polygon_id unique identifiers counties New Jersey w_area proportion polygon falls within cell weight value weight aggregation, determined multiplying w_area value cell secondary weight","code":""},{"path":"https://tcarleton.github.io/stagg/reference/pop_world_2015_era5.html","id":null,"dir":"Reference","previous_headings":"","what":"Global population weights — pop_world_2015_era5","title":"Global population weights — pop_world_2015_era5","text":"data.table returned ERA5 resolution running secondary_weights() population data 2015 LandScan Global Population Data","code":""},{"path":"https://tcarleton.github.io/stagg/reference/pop_world_2015_era5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global population weights — pop_world_2015_era5","text":"","code":"pop_world_2015_era5"},{"path":"https://tcarleton.github.io/stagg/reference/pop_world_2015_era5.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Global population weights — pop_world_2015_era5","text":"object class data.table (inherits data.frame) 380458 rows 3 columns.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/pop_world_2015_era5.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Global population weights — pop_world_2015_era5","text":"https://landscan.ornl.gov/","code":""},{"path":"https://tcarleton.github.io/stagg/reference/secondary_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Resample a raster of secondary weights — secondary_weights","title":"Resample a raster of secondary weights — secondary_weights","text":"secondary_weights() function resamples raster interest desired resolution outputs table weights use function overlay_weights().","code":""},{"path":"https://tcarleton.github.io/stagg/reference/secondary_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Resample a raster of secondary weights — secondary_weights","text":"","code":"secondary_weights(secondary_raster, grid = era5_grid, extent = \"full\")"},{"path":"https://tcarleton.github.io/stagg/reference/secondary_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Resample a raster of secondary weights — secondary_weights","text":"secondary_raster raster secondary variable, example cropland coverage population grid raster layer spatial resolution climate data extent optional extent crop secondary_raster faster processing. Format must compatible raster::crop(). default \"full\", resamples whole secondary raster without cropping.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/secondary_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Resample a raster of secondary weights — secondary_weights","text":"data.table secondary weights","code":""},{"path":"https://tcarleton.github.io/stagg/reference/secondary_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Resample a raster of secondary weights — secondary_weights","text":"","code":"secondary_weights_output <- secondary_weights(   secondary_raster = cropland_nj_2015, # A raster of cropland to resample                                        # and convert to a data.table   grid = era5_grid, # The grid to resample the secondary_raster to (`era5_grid`                     # is the default)   extent = \"full\" # The default, which resamples the whole secondary raster                   # without cropping (`'full'` is the default)   ) #> Checking for raster alignment #> Longitude coordinates do not match. Aligning longitudes to standard coordinates. #> Resampling secondary_raster #> Creating a table of weights  head(secondary_weights_output) #>         x     y    weight #>     <num> <num>     <num> #> 1: -76.25 41.75 0.2294976 #> 2: -76.00 41.75 0.2198315 #> 3: -75.75 41.75 0.1777267 #> 4: -75.50 41.75 0.1362904 #> 5: -75.25 41.75 0.1061073 #> 6: -75.00 41.75 0.1215708"},{"path":"https://tcarleton.github.io/stagg/reference/stagg-package.html","id":null,"dir":"Reference","previous_headings":"","what":"stagg: Spatiotemporal Aggregation for Climate Data — stagg-package","title":"stagg: Spatiotemporal Aggregation for Climate Data — stagg-package","text":"package (one paragraph).","code":""},{"path":"https://tcarleton.github.io/stagg/reference/stagg-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"stagg: Spatiotemporal Aggregation for Climate Data — stagg-package","text":"Maintainer: First Last first.last@example.com (ORCID)","code":""},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_bin.html","id":null,"dir":"Reference","previous_headings":"","what":"Bin transformation and aggregation of climate data — staggregate_bin","title":"Bin transformation and aggregation of climate data — staggregate_bin","text":"function staggregate_bin() aggregates climate data daily level, splits daily values bins, aggregates transformed values polygon level desired temporal scale.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_bin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bin transformation and aggregation of climate data — staggregate_bin","text":"","code":"staggregate_bin(   data,   overlay_weights,   daily_agg,   time_agg = \"month\",   start_date = NA,   time_interval = \"1 hour\",   bin_breaks )"},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_bin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bin transformation and aggregation of climate data — staggregate_bin","text":"data raster brick data transformed aggregated overlay_weights table weights can generated using function overlay_weights() daily_agg aggregate hourly values daily values prior transformation. Options 'sum', 'average', 'none' ('none' transform values without first aggregating daily level) time_agg temporal scale aggregate data . Options 'hour', 'day', 'month', 'year' ('hour' selected unless daily_agg = 'none') start_date date (time, applicable) first layer raster. input format compatible lubridate::as_datetime(), e.g. \"1991-10-29\" \"1991-10-29 00:00:00\". default NA since rasters usually already contain temporal information layer names need manually supplied. time_interval time interval layers raster aggregated. input format compatible seq(), e.g. '1 day' '3 months'. default '1 hour' argument required daily_agg 'none' start_date argument NA. bin_breaks vector bin boundaries split data ","code":""},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_bin.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bin transformation and aggregation of climate data — staggregate_bin","text":"","code":"bin_output <- staggregate_bin(   data = temp_nj_jun_2024_era5 - 273.15, # Climate data to transform and                                          # aggregate   overlay_weights = overlay_weights_nj, # Output from overlay_weights()   daily_agg = \"average\", # Average hourly values to produce daily values                          # before transformation   time_agg = \"month\", # Sum the transformed daily values across months   start_date = \"2024-06-01 00:00:00\", # The start date of the supplied data,                                       # only required if the layer name                                       # format is not compatible with stagg   time_interval = \"1 hour\", # The temporal interval of the supplied data,                             # required if daily_agg is not \"none\" or if the                             # start_date argument is not NA   bin_breaks = c(0, 2.5, 5, 7.5, 10) # Draw 6 bins from ninf to 0, 0 to 2.5,                                      # 2.5 to 5, 5 to 7.5, 7.5 to 10, 10 to                                      # inf   ) #> Rewriting the data's temporal metadata (layer names) to reflect a dataset starting on the supplied start date and with a temporal interval of 1 hour #> Averaging over 24 layers per day to get daily values #> Executing binning transformation #> Aggregating by polygon and month  head(bin_output) #>     year month poly_id bin_ninf_to_0 bin_0_to_2.5 bin_2.5_to_5 bin_5_to_7.5 #>    <num> <num>  <char>         <num>        <num>        <num>        <num> #> 1:  2024     6     011             0            0            0            0 #> 2:  2024     6     033             0            0            0            0 #> 3:  2024     6     015             0            0            0            0 #> 4:  2024     6     009             0            0            0            0 #> 5:  2024     6     007             0            0            0            0 #> 6:  2024     6     041             0            0            0            0 #>    bin_7.5_to_10 bin_10_to_inf #>            <num>         <num> #> 1:             0            30 #> 2:             0            30 #> 3:             0            30 #> 4:             0            30 #> 5:             0            30 #> 6:             0            30"},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_degree_days.html","id":null,"dir":"Reference","previous_headings":"","what":"Degree days transformation and aggregation of climate data — staggregate_degree_days","title":"Degree days transformation and aggregation of climate data — staggregate_degree_days","text":"function staggregate_degree_days() aggregates climate data daily level, performs degree days transformation daily values, aggregates transformed values polygon level desired temporal scale","code":""},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_degree_days.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Degree days transformation and aggregation of climate data — staggregate_degree_days","text":"","code":"staggregate_degree_days(   data,   overlay_weights,   time_agg = \"month\",   start_date = NA,   time_interval = \"1 hour\",   thresholds )"},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_degree_days.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Degree days transformation and aggregation of climate data — staggregate_degree_days","text":"data raster brick data transformed aggregated overlay_weights table weights can generated using function overlay_weights() time_agg temporal scale aggregate data . Options 'day', 'month', 'year' start_date date (time, applicable) first layer raster. input format compatible lubridate::as_datetime(), e.g. \"1991-10-29\" \"1991-10-29 00:00:00\". default NA since rasters usually already contain temporal information layer names need manually supplied. time_interval time interval layers raster aggregated. input format compatible seq(), e.g. '1 day' '3 months'. default '1 hour' argument required start_date argument NA. thresholds vector temperature thresholds critical crop","code":""},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_degree_days.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Degree days transformation and aggregation of climate data — staggregate_degree_days","text":"","code":"degree_days_output <- staggregate_degree_days(   data = temp_nj_jun_2024_era5 - 273.15, # Climate data to transform and                                          # aggregate   overlay_weights = overlay_weights_nj, # Output from overlay_weights()   time_agg = \"month\", # Sum the transformed daily values across months   start_date = \"2024-06-01 00:00:00\", # The start date of the supplied data,                                       # only required if the layer name                                       # format is not compatible with stagg   time_interval = \"1 hour\", # The temporal interval of the supplied data,                             # only required if the start_date is not NA   thresholds = c(0, 10, 20) # Calculate degree days above 0, 10, and 20                             # degrees Celsius   ) #> Rewriting the data's temporal metadata (layer names) to reflect a dataset starting on the supplied start date and with a temporal interval of 1 hour #> Skipping pre-transformation aggregation to daily level #> Executing degree days transformation #> Aggregating by polygon and month  head(degree_days_output) #>     year month poly_id threshold_ninf_to_0 threshold_0_to_10 threshold_10_to_20 #>    <num> <num>  <char>               <num>             <num>              <num> #> 1:  2024     6     011                   0              7200           7057.782 #> 2:  2024     6     033                   0              7200           6994.112 #> 3:  2024     6     015                   0              7200           6929.559 #> 4:  2024     6     009                   0              7200           7135.649 #> 5:  2024     6     007                   0              7200           6935.083 #> 6:  2024     6     041                   0              7200           6480.811 #>    threshold_20_to_inf #>                  <num> #> 1:            3179.867 #> 2:            3414.202 #> 3:            3365.634 #> 4:            2146.668 #> 5:            3407.180 #> 6:            2724.483"},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_polynomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Polynomial transformation and aggregation of climate data — staggregate_polynomial","title":"Polynomial transformation and aggregation of climate data — staggregate_polynomial","text":"function staggregate_polynomial() aggregates climate data daily level, raises daily values 1 nth power, aggregates transformed values polygon level desired temporal scale.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_polynomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Polynomial transformation and aggregation of climate data — staggregate_polynomial","text":"","code":"staggregate_polynomial(   data,   overlay_weights,   daily_agg,   time_agg = \"month\",   start_date = NA,   time_interval = \"1 hour\",   degree )"},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_polynomial.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Polynomial transformation and aggregation of climate data — staggregate_polynomial","text":"data raster brick data transformed aggregated overlay_weights table weights can generated using function overlay_weights() daily_agg aggregate hourly values daily values prior transformation. Options 'sum', 'average', 'none' ('none' transform values without first aggregating daily level) time_agg temporal scale aggregate data . Options 'hour', 'day', 'month', 'year' ('hour' selected unless daily_agg = 'none') start_date date (time, applicable) first layer raster. input format compatible lubridate::as_datetime(), e.g. \"1991-10-29\" \"1991-10-29 00:00:00\". default NA since rasters usually already contain temporal information layer names need manually supplied. time_interval time interval layers raster aggregated. input format compatible seq(), e.g. '1 day' '3 months'. default '1 hour' argument required daily_agg 'none' start_date argument NA. degree highest exponent raise data ","code":""},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_polynomial.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Polynomial transformation and aggregation of climate data — staggregate_polynomial","text":"","code":"polynomial_output <- staggregate_polynomial(   data = temp_nj_jun_2024_era5 - 273.15, # Climate data to transform and                                          # aggregate   overlay_weights = overlay_weights_nj, # Output from overlay_weights()   daily_agg = \"average\", # Average hourly values to produce daily values                          # before transformation   time_agg = \"month\", # Sum the transformed daily values across months   start_date = \"2024-06-01 00:00:00\", # The start date of the supplied data,                                       # only required if the layer name                                       # format is not compatible with stagg   time_interval = \"1 hour\", # The temporal interval of the supplied data,                             # required if daily_agg is not \"none\" or if the                             # start_date argument is not NA   degree = 4 # Highest order   ) #> Rewriting the data's temporal metadata (layer names) to reflect a dataset starting on the supplied start date and with a temporal interval of 1 hour #> Averaging over 24 layers per day to get daily values #> Executing polynomial transformation #> Aggregating by polygon and month  head(polynomial_output) #>     year month poly_id  order_1  order_2  order_3  order_4 #>    <num> <num>  <char>    <num>    <num>    <num>    <num> #> 1:  2024     6     011 726.5687 17749.71 437408.2 10873488 #> 2:  2024     6     033 733.6797 18116.46 451620.0 11364291 #> 3:  2024     6     015 728.9664 17889.96 443345.9 11091933 #> 4:  2024     6     009 686.7632 15826.99 367227.1  8579171 #> 5:  2024     6     007 730.9276 17985.27 446880.3 11210400 #> 6:  2024     6     041 683.5539 15879.92 375830.3  9051704"},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_spline.html","id":null,"dir":"Reference","previous_headings":"","what":"Restricted cubic spline transformation and aggregation of climate data — staggregate_spline","title":"Restricted cubic spline transformation and aggregation of climate data — staggregate_spline","text":"function staggregate_spline() aggregates climate data daily level, performs restricted cubic spline transformation daily values, aggregates transformed values polygon level desired temporal scale.","code":""},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_spline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Restricted cubic spline transformation and aggregation of climate data — staggregate_spline","text":"","code":"staggregate_spline(   data,   overlay_weights,   daily_agg,   time_agg = \"month\",   start_date = NA,   time_interval = \"1 hour\",   knot_locs )"},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_spline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Restricted cubic spline transformation and aggregation of climate data — staggregate_spline","text":"data raster brick data transformed aggregated overlay_weights table weights can generated using function overlay_weights() daily_agg aggregate hourly values daily values prior transformation. Options 'sum', 'average', 'none' ('none' transform values without first aggregating daily level) time_agg temporal scale aggregate data . Options 'hour', 'day', 'month', 'year' ('hour' selected unless daily_agg = 'none') start_date date (time, applicable) first layer raster. input format compatible lubridate::as_datetime(), e.g. \"1991-10-29\" \"1991-10-29 00:00:00\". default NA since rasters usually already contain temporal information layer names need manually supplied. time_interval time interval layers raster aggregated. input format compatible seq(), e.g. '1 day' '3 months'. default '1 hour' argument required daily_agg 'none' start_date argument NA. knot_locs place knots","code":""},{"path":"https://tcarleton.github.io/stagg/reference/staggregate_spline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Restricted cubic spline transformation and aggregation of climate data — staggregate_spline","text":"","code":"spline_output <- staggregate_spline( data = temp_nj_jun_2024_era5 - 273.15, # Climate data to transform and                                        # aggregate overlay_weights = overlay_weights_nj, # Output from overlay_weights() daily_agg = \"average\", # Average hourly values to produce daily values                        # before transformation time_agg = \"month\", # Sum the transformed daily values across months start_date = \"2024-06-01 00:00:00\", # The start date of the supplied data,                                     # only required if the layer name format                                     # is not compatible with stagg time_interval = \"1 hour\", # The temporal interval of the supplied data,                           # required if daily_agg is not \"none\" or if the                           # start_date argument is not NA knot_locs = c(0, 7.5, 12.5, 20) # Where to place knots ) #> Rewriting the data's temporal metadata (layer names) to reflect a dataset starting on the supplied start date and with a temporal interval of 1 hour #> Averaging over 24 layers per day to get daily values #> Executing spline transformation #> Aggregating by polygon and month  head(spline_output) #>     year month poly_id    value   term_1   term_2 #>    <num> <num>  <char>    <num>    <num>    <num> #> 1:  2024     6     011 726.5687 301176.6 61231.64 #> 2:  2024     6     033 733.6797 306509.9 62564.98 #> 3:  2024     6     015 728.9664 302974.9 61681.26 #> 4:  2024     6     009 686.7632 271322.6 53768.18 #> 5:  2024     6     007 730.9276 304445.8 62048.98 #> 6:  2024     6     041 683.5539 268988.1 53195.44"},{"path":"https://tcarleton.github.io/stagg/reference/temp_nj_jun_2024_era5.html","id":null,"dir":"Reference","previous_headings":"","what":"Temperature data for New Jersey in June — temp_nj_jun_2024_era5","title":"Temperature data for New Jersey in June — temp_nj_jun_2024_era5","text":"raster brick containing temperature data June 1, 2024 June 30, 2024 entire state New Jersey","code":""},{"path":"https://tcarleton.github.io/stagg/reference/temp_nj_jun_2024_era5.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temperature data for New Jersey in June — temp_nj_jun_2024_era5","text":"","code":"temp_nj_jun_2024_era5"},{"path":"https://tcarleton.github.io/stagg/reference/temp_nj_jun_2024_era5.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Temperature data for New Jersey in June — temp_nj_jun_2024_era5","text":"raster brick containing 720 layers, representing one hour temperature data degrees Kelvin total 30 days worth data","code":""}]
